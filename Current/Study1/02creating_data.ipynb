{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "We will focus on specific kinds of part-of-speech (POS), i.e.,\n",
    "- adjectives\n",
    "- verbs and nouns that form verbs when \"suru\" is added as a suffix\n",
    "- nouns "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mecab -o ./Results/output01_self.txt.mecab ./Results/output01_self.txt\n",
    "!mecab -o ./Results/output01_target.txt.mecab ./Results/output01_target.txt\n",
    "# !mecab -o ./test.txt.mecab ./test.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morphological Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_morphol(filename):\n",
    "\tsentences = []\n",
    "\tsentence = []\n",
    "\twith open(filename, mode='r') as f:\n",
    "\t\tfor line in f:\n",
    "\t\t\tif line != 'EOS\\n':\n",
    "\t\t\t\tfields = line.split('\\t')\n",
    "\t\t\t\tif len(fields) != 2 or fields[0] == '':\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tattr = fields[1].split(',')\n",
    "\t\t\t\t\tif attr[6] != '*\\n':\n",
    "\t\t\t\t\t\tmorph = {'surface': fields[0], 'base': attr[6], 'pos': attr[0], 'pos1': attr[1]}\n",
    "\t\t\t\t\t\tsentence.append(morph)\n",
    "\t\t\telse:\n",
    "\t\t\t\tsentences.append(sentence)\n",
    "\t\t\t\tsentence = []\n",
    "\t\n",
    "\treturn sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = './test.txt.mecab'\n",
    "# sentences = my_morphol(filename)\n",
    "# print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELF\n",
    "filename = './Results/output01_self.txt.mecab'\n",
    "sentences_self = my_morphol(filename)\n",
    "# for sentence in sentences_self:\n",
    "# \tprint(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TARGET\n",
    "filename = './Results/output01_target.txt.mecab'\n",
    "sentences_target = my_morphol(filename)\n",
    "# for sentence in sentences_target:\n",
    "# \tprint(sentence)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tokenization(sentences):\n",
    "\tsentences_token = []\n",
    "\tsentence_token = []\n",
    "\tfor sentence in sentences:\n",
    "\t\tfor morph in sentence:\n",
    "\t\t\t# POS according to https://www.gavo.t.u-tokyo.ac.jp/~mine/japanese/nlp+slp/NAIST-JDIC_manual.pdf\n",
    "\t\t\t# Words for Traits\n",
    "\t\t\tif morph['pos'] == '形容詞' and morph['pos1'] == '自立': # pos = 形容詞, pos1 = 自立\n",
    "\t\t\t\tsentence_token.append(morph['base'])\n",
    "\t\t\telif morph['pos'] == '名詞' and morph['pos1'] == '形容動詞語幹': # pos = 名詞, pos1 = 形容動詞語幹\n",
    "\t\t\t\tsentence_token.append(morph['base'])\n",
    "\t\t\telif morph['pos'] == '名詞' and morph['pos1'] == 'ナイ形容詞語幹': # pos = 名詞, pos1 = ナイ形容詞語幹\n",
    "\t\t\t\tsentence_token.append(morph['base'])\n",
    "\n",
    "\t\t\t# Words for Behaviors\n",
    "\t\t\telif morph['pos'] == '動詞' and morph['pos1'] == '自立': # pos = 動詞, pos1 = 自立\n",
    "\t\t\t\tsentence_token.append(morph['base'])\n",
    "\t\t\telif morph['pos'] == '名詞' and morph['pos1'] == 'サ変接続': # pos = 名詞, pos1 = サ変接続, \n",
    "\t\t\t\tsentence_token.append(morph['base'])\n",
    "\n",
    "\t\t\t# Words for Stereotype etc\n",
    "\t\t\telif morph['pos'] == '名詞' and morph['pos1'] == '一般': # pos = 名詞, 一般\n",
    "\t\t\t\tsentence_token.append(morph['base'])\n",
    "\t\t\telif morph['pos'] == '名詞' and morph['pos1'] == '固有名詞': # pos = 名詞, 固有名詞\n",
    "\t\t\t\tsentence_token.append(morph['base'])\n",
    "\t\t\telif morph['pos'] == '名詞' and morph['pos1'] == '代名詞': # pos = 名詞, 代名詞\n",
    "\t\t\t\tsentence_token.append(morph['base'])\n",
    "\n",
    "\t\tsentences_token.append(sentence_token)\n",
    "\t\tsentence_token = []\n",
    "\n",
    "\treturn sentences_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences_token = my_tokenization(sentences)\n",
    "# print(sentences_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELF\n",
    "sentences_token_self = my_tokenization(sentences_self)\n",
    "# for sentence in sentences_token_self:\n",
    "# \tprint(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TARGET\n",
    "sentences_token_target = my_tokenization(sentences_target)\n",
    "# for sentence in sentences_token_target:\n",
    "# \tprint(sentence)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indices\n",
    "overlapping magnitude"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An unoriented incidnece matrix A\n",
    "- unique words in rows\n",
    "- self and target in columns (self in the first column; target in the second column)\n",
    "- When word w_i represented in i-th row, is used to describe the self, the corresponding element a_i1 is 1, otherwise, 0."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A self-other overlap matrix\n",
    "tranpose(A) * A"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlapping magnitude\n",
    "n_12 / (n_11 + n_22 - n_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_magnitude_list = []\n",
    "for tokens_self, tokens_target in zip(sentences_token_self, sentences_token_target):\n",
    "\n",
    "\tif len(tokens_self) > 0 and len(tokens_target) > 0:\n",
    "\t\t# Create a dictionary\n",
    "\t\td = {\n",
    "\t\t\t'word': tokens_self + tokens_target,\n",
    "\t\t\t'cond': ['self'] * (len(tokens_self)) + ['target'] * (len(tokens_target))\n",
    "\t\t}\n",
    "\t\t# Create a dataframe\n",
    "\t\tdf = pd.DataFrame(data=d)\n",
    "\t\t# Create a crosstab\n",
    "\t\tctab = pd.crosstab(df['word'], df['cond'])\n",
    "\n",
    "\t\t# Create an Unoriented Incidence Matrix\n",
    "\t\tctab_bin = ctab > 0\t\t# 0 for 0, otherwise (>0) 1\n",
    "\t\tincidence_matrix = ctab_bin * 1 # covnert (True, False) to (1, 0)\n",
    "\t\n",
    "\t\t# Create a Co-Membership Matrix\n",
    "\t\tcomembership_matrix = incidence_matrix.T.dot(incidence_matrix)\n",
    "\n",
    "\t\t# Compute an Overlap Magnitude\n",
    "\t\tn12 = comembership_matrix.loc['self', 'target']\n",
    "\t\tn11 = comembership_matrix.loc['self', 'self']\n",
    "\t\tn22 = comembership_matrix.loc['target', 'target']\n",
    "\t\toverlap_magnitude = n12 / (n11 + n22 - n12)\n",
    "\t\n",
    "\telse:\n",
    "\t\toverlap_magnitude = 'NA'\n",
    "\t\n",
    "\toverlap_magnitude_list.append(overlap_magnitude)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overlap_magnitude_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation\n",
    "High IOS group (5, 6, 7) and Low IOS group (1, 2, and 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Results/output01_all.csv')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "HighIOS_indices = df['IOS_score'] > 4\n",
    "LowIOS_indices = df['IOS_score'] < 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_df = pd.DataFrame({\n",
    "# \t'SubID': ['NA','NA','NA','NA','NA','NA','NA','NA','NA','NA',\n",
    "# \t\t'NA','NA','NA','NA','NA','NA','NA','NA','NA','NA'],\n",
    "# \t'IOSScore': [1, 2, 3, 4, 5, 6, 7, 1, 2, 3,\n",
    "# \t\t\t4, 5, 6, 7, 1, 2, 3, 4, 5, 6],\n",
    "# \t'IOSGroup': ['H','H','H','H','H','H','H','H','H','H', \n",
    "# \t\t\t'L','L','L','L','L','L','L','L','L','L'],\n",
    "# \t'OverlapScore': [71, 72, 72, 75, 78, 81, 82, 83, 89, 91,\n",
    "# \t\t81, 81, 84, 88, 88, 89, 90, 90, 90, 91]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = df[['MID', 'IOS_score']].copy()\n",
    "out_df['Overlap_score'] = overlap_magnitude_list\n",
    "out_df['IOS_group'] = ['Neither'] * len(overlap_magnitude_list)\n",
    "out_df.loc[HighIOS_indices, ['IOS_group']] = 'HighIOS'\n",
    "out_df.loc[LowIOS_indices, ['IOS_group']] = 'LowIOS'\n",
    "\n",
    "filename = './Results/output02.csv'\n",
    "out_df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myproject02",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "93051bf13d83ec2e01d285bdca34cc099d877940d2925ef65c32d053070d16fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
