{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "We will focus on specific kinds of part-of-speech (POS), i.e.,\n",
    "- Adjectives\n",
    "- Verbs and nouns that form verbs when \"suru\" is added as a suffix\n",
    "- nouns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mecab -o ./Results/output01_self.txt.mecab ./Results/output01_self.txt\n",
    "!mecab -o ./Results/output01_target.txt.mecab ./Results/output01_target.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morphological Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_morphol(filename):\n",
    "\tsentences = []\n",
    "\tsentence = []\n",
    "\tprevious_line = ''\n",
    "\tMID = -1\n",
    "\twith open(filename, mode='r') as f:\n",
    "\t\tfor line in f:\n",
    "\t\t\t# headerに相当する最初の行をスキップ\n",
    "\t\t\t# 文頭 or 文中\n",
    "\t\t\tif line != 'EOS\\n':\n",
    "\t\t\t\tfields = line.split('\\t')\n",
    "\t\t\t\tattr = fields[1].split(',')\n",
    "\t\t\t\t# 変数名行\n",
    "\t\t\t\tif previous_line == '':\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\t# MID行\n",
    "\t\t\t\telif fields[0] == 'MID':\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\t# 文頭\n",
    "\t\t\t\telif previous_line == 'EOS\\n' and attr[1] == '数':\n",
    "\t\t\t\t\tMID = int(fields[0])\n",
    "\t\t\t\t\tsentence.append(MID)\n",
    "\t\t\t\t# 文中\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tmorph = {'surface': fields[0], 'base': attr[6], 'pos': attr[0], 'pos1': attr[1]}\n",
    "\t\t\t\t\tsentence.append(morph)\n",
    "\t\t\t# 文末（EOS行）\n",
    "\t\t\telse:\n",
    "\t\t\t\tif MID > 0 and len(sentence) > 0:\n",
    "\t\t\t\t\tsentences.append(sentence)\n",
    "\t\t\t\t\tsentence = []\n",
    "\t\t\t\t\tMID = -1\n",
    "\t\t\t\telif MID > 0 and len(sentence) == 0:\n",
    "\t\t\t\t\tsentences.append([])\n",
    "\t\t\t\t\tsentence = []\n",
    "\t\t\t\t\tMID = -1\n",
    "\n",
    "\t\t\tprevious_line = line\n",
    "\n",
    "\treturn sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELF\n",
    "filename = './Results/output01_self.txt.mecab'\n",
    "sentences_self = my_morphol(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " {'surface': '.', 'base': '*\\n', 'pos': '名詞', 'pos1': 'サ変接続'},\n",
       " {'surface': '0', 'base': '*\\n', 'pos': '名詞', 'pos1': '数'},\n",
       " {'surface': '回答', 'base': '回答', 'pos': '名詞', 'pos1': 'サ変接続'},\n",
       " {'surface': '梨', 'base': '梨', 'pos': '名詞', 'pos1': '一般'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_self[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "479"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences_self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TARGET\n",
    "filename = './Results/output01_target.txt.mecab'\n",
    "sentences_target = my_morphol(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " {'surface': '.', 'base': '*\\n', 'pos': '名詞', 'pos1': 'サ変接続'},\n",
       " {'surface': '0', 'base': '*\\n', 'pos': '名詞', 'pos1': '数'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "479"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences_target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tokenization(sentences):\n",
    "\tsentences_token = []\n",
    "\tsentence_token = []\n",
    "\tfor sentence in sentences:\n",
    "\t\t# sentence[0] = MID\n",
    "\t\tsentence_token.append(sentence[0])\n",
    "\n",
    "\t\tfor morph in sentence[1:]:\n",
    "\t\t\t# POS according to https://www.gavo.t.u-tokyo.ac.jp/~mine/japanese/nlp+slp/NAIST-JDIC_manual.pdf\n",
    "\t\t\t# Words for Traits\n",
    "\t\t\tif morph['pos'] == '形容詞' and morph['pos1'] == '自立':\n",
    "\t\t\t\tsentence_token.append(morph['base'])\n",
    "\t\t\telif morph['pos'] == '名詞' and morph['pos1'] == '形容動詞語幹':\n",
    "\t\t\t\tif morph['base'] != '*\\n':\n",
    "\t\t\t\t\tsentence_token.append(morph['base'])\n",
    "\t\t\telif morph['pos'] == '名詞' and morph['pos1'] == 'ナイ形容詞語幹':\n",
    "\t\t\t\tif morph['base'] != '*\\n':\n",
    "\t\t\t\t\tsentence_token.append(morph['base'])\n",
    "\n",
    "\t\t\t# Words for Behaviors\n",
    "\t\t\telif morph['pos'] == '動詞' and morph['pos1'] == '自立':\n",
    "\t\t\t\tsentence_token.append(morph['base'])\n",
    "\t\t\telif morph['pos'] == '名詞' and morph['pos1'] == 'サ変接続':\n",
    "\t\t\t\tif morph['base'] != '*\\n':\t# e.g, {'surface': '､', 'base': '*\\n', 'pos': '名詞', 'pos1': 'サ変接続'}\n",
    "\t\t\t\t\tsentence_token.append(morph['base'])\n",
    "\n",
    "\t\t\t# Words for Stereotype etc\n",
    "\t\t\telif morph['pos'] == '名詞' and morph['pos1'] == '一般':\n",
    "\t\t\t\tif morph['base'] != '*\\n':\t# e.g., {'surface': 'キャパオーバー', 'base': '*\\n', 'pos': '名詞', 'pos1': '一般'},\n",
    "\t\t\t\t\tsentence_token.append(morph['base'])\n",
    "\t\t\telif morph['pos'] == '名詞' and morph['pos1'] == '固有名詞':\n",
    "\t\t\t\tif morph['base'] != '*\\n':\t# {'surface': 'k', 'base': '*\\n', 'pos': '名詞', 'pos1': '固有名詞'}\n",
    "\t\t\t\t\tsentence_token.append(morph['base'])\n",
    "\t\t\telif morph['pos'] == '名詞' and morph['pos1'] == '代名詞':\n",
    "\t\t\t\tif morph['base'] != '*\\n':\n",
    "\t\t\t\t\tsentence_token.append(morph['base'])\n",
    "\n",
    "\t\tsentences_token.append(sentence_token)\n",
    "\t\tsentence_token = []\n",
    "\n",
    "\treturn sentences_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def my_tokenization(sentences):\n",
    "# \tsentences_token = []\n",
    "# \tsentence_token = []\n",
    "# \tfor sentence in sentences:\n",
    "# \t\t# sentence[0] = MID\n",
    "# \t\tsentence_token.append(sentence[0])\n",
    "# \n",
    "# \t\tfor morph in sentence[1:]:\n",
    "# \t\t\t# POS according to https://www.gavo.t.u-tokyo.ac.jp/~mine/japanese/nlp+slp/NAIST-JDIC_manual.pdf\n",
    "# \t\t\t# Words for Traits\n",
    "# \t\t\tif morph['pos'] == '形容詞' and morph['pos1'] == '自立': # pos = 形容詞, pos1 = 自立\n",
    "# \t\t\t\tsentence_token.append(morph['base'])\n",
    "# \t\t\telif morph['pos'] == '名詞' and morph['pos1'] == '形容動詞語幹': # pos = 名詞, pos1 = 形容動詞語幹\n",
    "# \t\t\t\tsentence_token.append(morph['base'])\n",
    "# \t\t\telif morph['pos'] == '名詞' and morph['pos1'] == 'ナイ形容詞語幹': # pos = 名詞, pos1 = ナイ形容詞語幹\n",
    "# \t\t\t\tsentence_token.append(morph['base'])\n",
    "# \n",
    "# \t\t\t# Words for Behaviors\n",
    "# \t\t\telif morph['pos'] == '動詞' and morph['pos1'] == '自立': # pos = 動詞, pos1 = 自立\n",
    "# \t\t\t\tsentence_token.append(morph['base'])\n",
    "# \t\t\telif morph['pos'] == '名詞' and morph['pos1'] == 'サ変接続': # pos = 名詞, pos1 = サ変接続, \n",
    "# \t\t\t\tsentence_token.append(morph['base'])\n",
    "# \n",
    "# \t\t\t# Words for Stereotype etc\n",
    "# \t\t\telif morph['pos'] == '名詞' and morph['pos1'] == '一般': # pos = 名詞, 一般\n",
    "# \t\t\t\tif morph['base'] == '*\\n': # e.g., {'surface': 'キャパオーバー', 'base': '*\\n', 'pos': '名詞', 'pos1': '一般'},\n",
    "# \t\t\t\t\tsentence_token.append(morph['surface'])\n",
    "# \t\t\t\telse:\n",
    "# \t\t\t\t\tsentence_token.append(morph['base'])\n",
    "# \t\t\telif morph['pos'] == '名詞' and morph['pos1'] == '固有名詞': # pos = 名詞, 固有名詞\n",
    "# \t\t\t\tif morph['base'] == '*\\n': # {'surface': 'k', 'base': '*\\n', 'pos': '名詞', 'pos1': '固有名詞'}\n",
    "# \t\t\t\t\tsentence_token.append(morph['surface'])\n",
    "# \t\t\t\telse:\n",
    "# \t\t\t\t\tsentence_token.append(morph['base'])\n",
    "# \t\t\telif morph['pos'] == '名詞' and morph['pos1'] == '代名詞': # pos = 名詞, 代名詞\n",
    "# \t\t\t\tsentence_token.append(morph['base'])\n",
    "# \n",
    "# \t\tsentences_token.append(sentence_token)\n",
    "# \t\tsentence_token = []\n",
    "# \n",
    "# \treturn sentences_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELF\n",
    "sentences_token_self = my_tokenization(sentences_self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, '回答', '梨']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_token_self[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TARGET\n",
    "sentences_token_target = my_tokenization(sentences_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_token_target[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Vec Similarity (self vs. target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing a word vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model_path = '../../Materials/word2vec.gensim.model'\n",
    "model = Word2Vec.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Economic', 0.9120144248008728),\n",
       " ('Organization', 0.9098771810531616),\n",
       " ('science', 0.9062338471412659),\n",
       " ('Law', 0.9048188924789429),\n",
       " ('Studies', 0.9007666110992432),\n",
       " ('Education', 0.8942281007766724),\n",
       " ('Political', 0.8923444747924805),\n",
       " ('Society', 0.8902304172515869),\n",
       " ('Science', 0.8886737823486328),\n",
       " ('Medicine', 0.8862507939338684)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 確認：類似語\n",
    "model.wv.most_similar(positive=['Social'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0544568   0.13679808 -0.35749108  0.05034312 -0.018448    0.15091987\n",
      " -0.12394528 -0.09055351 -0.20597099 -0.1876517   0.1110284   0.07684731\n",
      " -0.07806271 -0.0162644  -0.18043248  0.10543583  0.19625992  0.05441505\n",
      " -0.41463816  0.29697278  0.11950846  0.08052836 -0.09025036  0.02078868\n",
      "  0.16672397 -0.19404823  0.08641643  0.09545647 -0.06334688 -0.12846425\n",
      "  0.05050173 -0.10663079  0.1275091   0.09031986  0.09797987  0.05163022\n",
      "  0.0304911   0.02613543  0.17335036 -0.18157065  0.0181381   0.02991033\n",
      "  0.24255605  0.07176003  0.03419382  0.13056698 -0.03153648 -0.09767581\n",
      "  0.05309673  0.09953102]\n",
      "(50,)\n"
     ]
    }
   ],
   "source": [
    "# 確認：分散表現\n",
    "word_vec = model.wv[u'単語']\n",
    "print(word_vec)\n",
    "print(np.transpose(word_vec).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaged word vec for self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: MID = 13, idx = 5, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 38, idx = 13, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 47, idx = 18,  \"Key 'はなしかける' not present\"\n",
      "Warning: MID = 51, idx = 19, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 73, idx = 25, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 75, idx = 26, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 85, idx = 33,  \"Key '取りえ' not present\"\n",
      "KeyError: MID = 92, idx = 36,  \"Key '弁える' not present\"\n",
      "Warning: MID = 94, idx = 37, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 102, idx = 42, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 112, idx = 45,  \"Key '誘える' not present\"\n",
      "KeyError: MID = 122, idx = 50,  \"Key 'しれる' not present\"\n",
      "Warning: MID = 135, idx = 58, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 136, idx = 59,  \"Key '煮えくり返る' not present\"\n",
      "Warning: MID = 142, idx = 62, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 151, idx = 67, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 169, idx = 75,  \"Key 'めんどい' not present\"\n",
      "Warning: MID = 175, idx = 79, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 178, idx = 82, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 182, idx = 85, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 184, idx = 86, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 195, idx = 90, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 196, idx = 91,  \"Key 'おっくう' not present\"\n",
      "KeyError: MID = 205, idx = 95,  \"Key '思いだす' not present\"\n",
      "Warning: MID = 209, idx = 97, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 214, idx = 98,  \"Key 'しなう' not present\"\n",
      "Warning: MID = 217, idx = 99, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 225, idx = 103,  \"Key '尽くせる' not present\"\n",
      "KeyError: MID = 225, idx = 103,  \"Key '尽くせる' not present\"\n",
      "KeyError: MID = 225, idx = 103,  \"Key '尽くせる' not present\"\n",
      "Warning: MID = 237, idx = 112, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 255, idx = 122, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 267, idx = 127,  \"Key 'なげる' not present\"\n",
      "KeyError: MID = 273, idx = 131,  \"Key 'いらち' not present\"\n",
      "Warning: MID = 276, idx = 134, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 290, idx = 142, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 309, idx = 151,  \"Key 'ことわれる' not present\"\n",
      "KeyError: MID = 309, idx = 151,  \"Key 'まっとうする' not present\"\n",
      "KeyError: MID = 320, idx = 160,  \"Key '人後' not present\"\n",
      "KeyError: MID = 333, idx = 168,  \"Key '猫かぶり' not present\"\n",
      "KeyError: MID = 333, idx = 168,  \"Key '猫かぶり' not present\"\n",
      "KeyError: MID = 341, idx = 172,  \"Key 'かんじる' not present\"\n",
      "KeyError: MID = 344, idx = 174,  \"Key 'つきあえる' not present\"\n",
      "Warning: MID = 346, idx = 175, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 351, idx = 177,  \"Key 'めんどくさい' not present\"\n",
      "Warning: MID = 353, idx = 179, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 360, idx = 184, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 362, idx = 185, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 363, idx = 186,  \"Key 'しれる' not present\"\n",
      "KeyError: MID = 381, idx = 190,  \"Key '活かる' not present\"\n",
      "Warning: MID = 382, idx = 191, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 401, idx = 202, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 402, idx = 203,  \"Key 'かかわりあう' not present\"\n",
      "KeyError: MID = 406, idx = 206,  \"Key 'なあなあ' not present\"\n",
      "KeyError: MID = 448, idx = 232,  \"Key 'くちばしる' not present\"\n",
      "KeyError: MID = 466, idx = 239,  \"Key 'めんどくさい' not present\"\n",
      "KeyError: MID = 467, idx = 240,  \"Key '世辞' not present\"\n",
      "Warning: MID = 468, idx = 241, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 483, idx = 248, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 484, idx = 249, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 485, idx = 250, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 486, idx = 251, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 490, idx = 254,  \"Key 'でしゃばる' not present\"\n",
      "Warning: MID = 495, idx = 257, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 507, idx = 267,  \"Key '戸締まり' not present\"\n",
      "Warning: MID = 511, idx = 268, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 512, idx = 269, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 516, idx = 272,  \"Key 'やりとげる' not present\"\n",
      "Warning: MID = 532, idx = 281, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 534, idx = 283, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 537, idx = 286,  \"Key 'しれる' not present\"\n",
      "Warning: MID = 556, idx = 297, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 557, idx = 298,  \"Key 'くよくよ' not present\"\n",
      "KeyError: MID = 573, idx = 310,  \"Key '世辞' not present\"\n",
      "KeyError: MID = 587, idx = 322,  \"Key '話し込む' not present\"\n",
      "KeyError: MID = 596, idx = 328,  \"Key 'わきまえる' not present\"\n",
      "Warning: MID = 597, idx = 329, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 608, idx = 334,  \"Key 'しれる' not present\"\n",
      "KeyError: MID = 609, idx = 335,  \"Key 'めんどい' not present\"\n",
      "Warning: MID = 623, idx = 340, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 625, idx = 341,  \"Key '誘える' not present\"\n",
      "KeyError: MID = 630, idx = 343,  \"Key '対す' not present\"\n",
      "KeyError: MID = 633, idx = 345,  \"Key '火の元' not present\"\n",
      "Warning: MID = 650, idx = 355, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 660, idx = 359, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 674, idx = 364,  \"Key '喜べる' not present\"\n",
      "Warning: MID = 676, idx = 366, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 678, idx = 368,  \"Key '面倒い' not present\"\n",
      "KeyError: MID = 685, idx = 372,  \"Key '自若' not present\"\n",
      "KeyError: MID = 695, idx = 377,  \"Key '仏頂面' not present\"\n",
      "Warning: MID = 702, idx = 381, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 714, idx = 385, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 718, idx = 388, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 725, idx = 390, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 738, idx = 396, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 766, idx = 403,  \"Key '面倒臭い' not present\"\n",
      "Warning: MID = 767, idx = 404, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 780, idx = 409,  \"Key '先走る' not present\"\n",
      "Warning: MID = 783, idx = 411, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 785, idx = 413, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 790, idx = 416,  \"Key 'うかれる' not present\"\n",
      "KeyError: MID = 798, idx = 419,  \"Key '喜べる' not present\"\n",
      "KeyError: MID = 798, idx = 419,  \"Key '鬱気' not present\"\n",
      "KeyError: MID = 807, idx = 424,  \"Key '見知り' not present\"\n",
      "Warning: MID = 812, idx = 427, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 826, idx = 434, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 829, idx = 435,  \"Key '別け隔て' not present\"\n",
      "Warning: MID = 833, idx = 437, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 840, idx = 440, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 848, idx = 444, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 851, idx = 445, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 852, idx = 446, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 863, idx = 451, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 867, idx = 454, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 885, idx = 460, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 892, idx = 462, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 898, idx = 463, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 904, idx = 466, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 906, idx = 467, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 913, idx = 470,  \"Key 'しゃしゃり出る' not present\"\n",
      "KeyError: MID = 920, idx = 474,  \"Key 'ていっぱい' not present\"\n",
      "KeyError: MID = 921, idx = 475,  \"Key 'みしる' not present\"\n",
      "KeyError: MID = 921, idx = 475,  \"Key 'みしる' not present\"\n",
      "KeyError: MID = 924, idx = 478,  \"Key '軽々しい' not present\"\n",
      "KeyError: MID = 924, idx = 478,  \"Key 'はなれる' not present\"\n"
     ]
    }
   ],
   "source": [
    "# Compute averaged vectors for SELF\n",
    "mid_list = []\n",
    "word_vec_avg_list = []\n",
    "for i, tokens in enumerate(sentences_token_self):\n",
    "\n",
    "    word_vec_arr = []\n",
    "    for token in tokens[1:]:\n",
    "        try:\n",
    "            word_vec_arr.append(model.wv[token])\n",
    "        except KeyError as e:\n",
    "            print(f'KeyError: MID = {tokens[0]}, idx = {i}, ', e)\n",
    "\n",
    "    if len(word_vec_arr) > 0:\n",
    "        word_vec_arr = np.asarray(word_vec_arr)\n",
    "        word_vec_avg = np.average(word_vec_arr, axis=0)\n",
    "    else:\n",
    "        print(f'Warning: MID = {tokens[0]}, idx = {i}, the word_vec_arr is empty, replaced by NaN.')\n",
    "        word_vec_avg = np.nan\n",
    "\n",
    "    mid_list.append(tokens[0])\n",
    "    word_vec_avg_list.append(word_vec_avg)\n",
    "\n",
    "word_vec_df_self = pd.DataFrame([mid_list, word_vec_avg_list], index=['MID', 'word_vec_avg_self']).T\n",
    "word_vec_df_self.set_index('MID', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_vec_avg_self</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.12554576, -0.009165149, -0.12818073, -0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[-0.017000489, 0.021428036, 0.16119394, -0.009...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.038041864, 0.046753965, 0.08819873, 0.00072...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[-0.06192059, -0.11488108, 0.11417292, -0.0890...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0.08219984, 0.03136838, 0.149636, 0.06478363,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     word_vec_avg_self\n",
       "MID                                                   \n",
       "2    [-0.12554576, -0.009165149, -0.12818073, -0.08...\n",
       "5    [-0.017000489, 0.021428036, 0.16119394, -0.009...\n",
       "7    [0.038041864, 0.046753965, 0.08819873, 0.00072...\n",
       "8    [-0.06192059, -0.11488108, 0.11417292, -0.0890...\n",
       "11   [0.08219984, 0.03136838, 0.149636, 0.06478363,..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vec_df_self.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_vec_avg_self</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>[0.07969623, -0.03585144, 0.0949019, -0.020791...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>[0.11347691, 0.0692842, 0.0929859, -0.01711248...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>[-0.039919835, 0.022903582, 0.13555361, 0.0990...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>[0.086014, -0.08224651, 0.10696781, 0.04868111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>[0.074476875, 0.0024441672, 0.101361, 0.010703...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     word_vec_avg_self\n",
       "MID                                                   \n",
       "920  [0.07969623, -0.03585144, 0.0949019, -0.020791...\n",
       "921  [0.11347691, 0.0692842, 0.0929859, -0.01711248...\n",
       "922  [-0.039919835, 0.022903582, 0.13555361, 0.0990...\n",
       "923  [0.086014, -0.08224651, 0.10696781, 0.04868111...\n",
       "924  [0.074476875, 0.0024441672, 0.101361, 0.010703..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vec_df_self.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "479"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_vec_df_self)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaged word vec for target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: MID = 2, idx = 0, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 11, idx = 4, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 13, idx = 5, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 30, idx = 9,  \"Key 'でしゃばる' not present\"\n",
      "KeyError: MID = 40, idx = 14,  \"Key 'かんじる' not present\"\n",
      "Warning: MID = 42, idx = 16, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 51, idx = 19, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 52, idx = 20, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 64, idx = 22,  \"Key '少い' not present\"\n",
      "Warning: MID = 65, idx = 23, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 75, idx = 26, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 76, idx = 27, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 78, idx = 28,  \"Key 'しれる' not present\"\n",
      "Warning: MID = 80, idx = 30, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 81, idx = 31, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 92, idx = 36, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 105, idx = 43, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 124, idx = 52, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 131, idx = 55, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 149, idx = 66, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 156, idx = 70, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 169, idx = 75,  \"Key 'しれる' not present\"\n",
      "Warning: MID = 175, idx = 79, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 181, idx = 84, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 193, idx = 89,  \"Key 'お互い様' not present\"\n",
      "KeyError: MID = 202, idx = 94,  \"Key 'いけ好かない' not present\"\n",
      "Warning: MID = 209, idx = 97, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 239, idx = 114, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 244, idx = 116, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 256, idx = 123, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 257, idx = 124, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 273, idx = 131, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 277, idx = 135, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 284, idx = 138,  \"Key '面倒い' not present\"\n",
      "Warning: MID = 294, idx = 143, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 299, idx = 144, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 303, idx = 146, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 312, idx = 154,  \"Key 'やりこなす' not present\"\n",
      "Warning: MID = 313, idx = 155, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 315, idx = 157, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 316, idx = 158, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 333, idx = 168,  \"Key 'あたためる' not present\"\n",
      "KeyError: MID = 338, idx = 170,  \"Key 'かんじる' not present\"\n",
      "KeyError: MID = 341, idx = 172,  \"Key 'かんじる' not present\"\n",
      "KeyError: MID = 342, idx = 173,  \"Key 'そこねる' not present\"\n",
      "Warning: MID = 344, idx = 174, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 352, idx = 178, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 354, idx = 180,  \"Key '気安い' not present\"\n",
      "KeyError: MID = 359, idx = 183,  \"Key 'やりとげる' not present\"\n",
      "Warning: MID = 386, idx = 193, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 399, idx = 201, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 402, idx = 203, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 405, idx = 205, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 421, idx = 215, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 428, idx = 220, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 432, idx = 222,  \"Key 'しれる' not present\"\n",
      "KeyError: MID = 432, idx = 222,  \"Key '思い切る' not present\"\n",
      "KeyError: MID = 435, idx = 225,  \"Key '黙る' not present\"\n",
      "Warning: MID = 459, idx = 236, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 463, idx = 237, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 466, idx = 239, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 467, idx = 240,  \"Key 'おちょこ' not present\"\n",
      "KeyError: MID = 480, idx = 246,  \"Key 'チャキチャキ' not present\"\n",
      "KeyError: MID = 490, idx = 254,  \"Key '客商売' not present\"\n",
      "Warning: MID = 494, idx = 256, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 502, idx = 262, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 505, idx = 265, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 506, idx = 266,  \"Key 'なす事' not present\"\n",
      "KeyError: MID = 506, idx = 266,  \"Key 'しれる' not present\"\n",
      "KeyError: MID = 506, idx = 266,  \"Key 'かわいがる' not present\"\n",
      "KeyError: MID = 533, idx = 282,  \"Key '積和不動産' not present\"\n",
      "Warning: MID = 535, idx = 284, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 541, idx = 288, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 550, idx = 291,  \"Key '能無し' not present\"\n",
      "Warning: MID = 558, idx = 299, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 566, idx = 304, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 572, idx = 309, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 577, idx = 314,  \"Key 'いちゃもん' not present\"\n",
      "KeyError: MID = 577, idx = 314,  \"Key 'ほったらかす' not present\"\n",
      "Warning: MID = 579, idx = 316, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 582, idx = 318,  \"Key 'とっつく' not present\"\n",
      "KeyError: MID = 587, idx = 322,  \"Key '聞かす' not present\"\n",
      "KeyError: MID = 587, idx = 322,  \"Key '人気もの' not present\"\n",
      "Warning: MID = 598, idx = 330, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 602, idx = 332, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 608, idx = 334,  \"Key 'やりとげる' not present\"\n",
      "Warning: MID = 615, idx = 338, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 625, idx = 341,  \"Key '面倒い' not present\"\n",
      "KeyError: MID = 631, idx = 344,  \"Key 'はしょる' not present\"\n",
      "Warning: MID = 634, idx = 346, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 643, idx = 352,  \"Key 'なごむ' not present\"\n",
      "Warning: MID = 673, idx = 363, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 674, idx = 364, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 675, idx = 365, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 677, idx = 367, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 681, idx = 369, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 686, idx = 373,  \"Key '不馴れ' not present\"\n",
      "Warning: MID = 691, idx = 375, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 695, idx = 377,  \"Key '仏頂面' not present\"\n",
      "KeyError: MID = 700, idx = 380,  \"Key '長話' not present\"\n",
      "Warning: MID = 702, idx = 381, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 712, idx = 383, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 725, idx = 390, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 726, idx = 391, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 732, idx = 392, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 733, idx = 393, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 736, idx = 395, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 738, idx = 396, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 745, idx = 399, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 774, idx = 406, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 783, idx = 411, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 807, idx = 424,  \"Key 'めんどうい' not present\"\n",
      "Warning: MID = 812, idx = 427, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 818, idx = 430,  \"Key 'めんどい' not present\"\n",
      "Warning: MID = 825, idx = 433, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 829, idx = 435, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 833, idx = 437, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 844, idx = 442, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 863, idx = 451, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 868, idx = 455, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 885, idx = 460, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 886, idx = 461,  \"Key 'かんがみる' not present\"\n",
      "KeyError: MID = 892, idx = 462,  \"Key 'いなす' not present\"\n",
      "Warning: MID = 898, idx = 463, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 899, idx = 464, the word_vec_arr is empty, replaced by NaN.\n",
      "Warning: MID = 908, idx = 468, the word_vec_arr is empty, replaced by NaN.\n",
      "KeyError: MID = 913, idx = 470,  \"Key 'しゃしゃり出る' not present\"\n",
      "KeyError: MID = 913, idx = 470,  \"Key 'しゃしゃり出る' not present\"\n",
      "KeyError: MID = 924, idx = 478,  \"Key 'ずば抜ける' not present\"\n"
     ]
    }
   ],
   "source": [
    "# Compute averaged vectors for TARGET\n",
    "mid_list = []\n",
    "word_vec_avg_list = []\n",
    "for i, tokens in enumerate(sentences_token_target):\n",
    "\n",
    "    word_vec_arr = []\n",
    "    for token in tokens[1:]:\n",
    "        try:\n",
    "            word_vec_arr.append(model.wv[token])\n",
    "        except KeyError as e:\n",
    "            print(f'KeyError: MID = {tokens[0]}, idx = {i}, ', e)\n",
    "\n",
    "    if len(word_vec_arr) > 0:\n",
    "        word_vec_arr = np.asarray(word_vec_arr)\n",
    "        word_vec_avg = np.average(word_vec_arr, axis=0)\n",
    "    else:\n",
    "        print(f'Warning: MID = {tokens[0]}, idx = {i}, the word_vec_arr is empty, replaced by NaN.')\n",
    "        word_vec_avg = np.nan\n",
    "\n",
    "    mid_list.append(tokens[0])\n",
    "    word_vec_avg_list.append(word_vec_avg)\n",
    "\n",
    "word_vec_df_target = pd.DataFrame([mid_list, word_vec_avg_list], index=['MID', 'word_vec_avg_target']).T\n",
    "word_vec_df_target.set_index('MID', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_vec_avg_target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.006501836, 0.06303416, 0.18272737, 0.021416...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.20633665, -0.07933207, 0.15059035, -0.01459...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.12936483, 0.014520218, -0.005053561, -0.024...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11.0</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    word_vec_avg_target\n",
       "MID                                                    \n",
       "2.0                                                 NaN\n",
       "5     [0.006501836, 0.06303416, 0.18272737, 0.021416...\n",
       "7     [0.20633665, -0.07933207, 0.15059035, -0.01459...\n",
       "8     [0.12936483, 0.014520218, -0.005053561, -0.024...\n",
       "11.0                                                NaN"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vec_df_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_vec_avg_target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>[0.03636287, -0.050786536, 0.035727605, 0.0401...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>[0.0512184, -0.032259293, 0.0640789, -0.060070...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>[-0.052868187, 0.00424375, 0.15772448, 0.01693...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>[0.08895031, -0.031109171, 0.096120544, 0.0478...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>[0.04499862, 0.028445652, 0.08161835, 0.033476...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   word_vec_avg_target\n",
       "MID                                                   \n",
       "920  [0.03636287, -0.050786536, 0.035727605, 0.0401...\n",
       "921  [0.0512184, -0.032259293, 0.0640789, -0.060070...\n",
       "922  [-0.052868187, 0.00424375, 0.15772448, 0.01693...\n",
       "923  [0.08895031, -0.031109171, 0.096120544, 0.0478...\n",
       "924  [0.04499862, 0.028445652, 0.08161835, 0.033476..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vec_df_target.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "479"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_vec_df_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge the two dataframes (self and target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vec_df_both = pd.merge(word_vec_df_self, word_vec_df_target, on='MID', how='outer', indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_vec_avg_self</th>\n",
       "      <th>word_vec_avg_target</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.12554576, -0.009165149, -0.12818073, -0.08...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[-0.017000489, 0.021428036, 0.16119394, -0.009...</td>\n",
       "      <td>[0.006501836, 0.06303416, 0.18272737, 0.021416...</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.038041864, 0.046753965, 0.08819873, 0.00072...</td>\n",
       "      <td>[0.20633665, -0.07933207, 0.15059035, -0.01459...</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[-0.06192059, -0.11488108, 0.11417292, -0.0890...</td>\n",
       "      <td>[0.12936483, 0.014520218, -0.005053561, -0.024...</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0.08219984, 0.03136838, 0.149636, 0.06478363,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     word_vec_avg_self  \\\n",
       "MID                                                      \n",
       "2    [-0.12554576, -0.009165149, -0.12818073, -0.08...   \n",
       "5    [-0.017000489, 0.021428036, 0.16119394, -0.009...   \n",
       "7    [0.038041864, 0.046753965, 0.08819873, 0.00072...   \n",
       "8    [-0.06192059, -0.11488108, 0.11417292, -0.0890...   \n",
       "11   [0.08219984, 0.03136838, 0.149636, 0.06478363,...   \n",
       "\n",
       "                                   word_vec_avg_target _merge  \n",
       "MID                                                            \n",
       "2                                                  NaN   both  \n",
       "5    [0.006501836, 0.06303416, 0.18272737, 0.021416...   both  \n",
       "7    [0.20633665, -0.07933207, 0.15059035, -0.01459...   both  \n",
       "8    [0.12936483, 0.014520218, -0.005053561, -0.024...   both  \n",
       "11                                                 NaN   both  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vec_df_both.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_vec_avg_self</th>\n",
       "      <th>word_vec_avg_target</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [word_vec_avg_self, word_vec_avg_target, _merge]\n",
       "Index: []"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vec_df_both.loc[word_vec_df_both['_merge'] != 'both', :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Vec Similarity between Self and Target\n",
    "cf. https://wakame-msds.com/similarity/\n",
    "- Euclidean Distance: the curse of dimensionality\n",
    "- Manhattan Distance: better than the Euclidean\n",
    "- Cosine Similarity: does not take accoung or the magnitude of each vector (only directions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_vec_avg_self</th>\n",
       "      <th>word_vec_avg_target</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[-0.017000489, 0.021428036, 0.16119394, -0.009...</td>\n",
       "      <td>[0.006501836, 0.06303416, 0.18272737, 0.021416...</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.038041864, 0.046753965, 0.08819873, 0.00072...</td>\n",
       "      <td>[0.20633665, -0.07933207, 0.15059035, -0.01459...</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[-0.06192059, -0.11488108, 0.11417292, -0.0890...</td>\n",
       "      <td>[0.12936483, 0.014520218, -0.005053561, -0.024...</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[0.055738714, 0.007035163, 0.107713476, 0.1542...</td>\n",
       "      <td>[0.14732212, 0.024135005, 0.045808703, 0.07718...</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[0.097340696, -0.0072463155, 0.11122257, 0.002...</td>\n",
       "      <td>[0.07632324, 0.00717866, 0.11950432, -0.000946...</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     word_vec_avg_self  \\\n",
       "MID                                                      \n",
       "5    [-0.017000489, 0.021428036, 0.16119394, -0.009...   \n",
       "7    [0.038041864, 0.046753965, 0.08819873, 0.00072...   \n",
       "8    [-0.06192059, -0.11488108, 0.11417292, -0.0890...   \n",
       "24   [0.055738714, 0.007035163, 0.107713476, 0.1542...   \n",
       "27   [0.097340696, -0.0072463155, 0.11122257, 0.002...   \n",
       "\n",
       "                                   word_vec_avg_target _merge  \n",
       "MID                                                            \n",
       "5    [0.006501836, 0.06303416, 0.18272737, 0.021416...   both  \n",
       "7    [0.20633665, -0.07933207, 0.15059035, -0.01459...   both  \n",
       "8    [0.12936483, 0.014520218, -0.005053561, -0.024...   both  \n",
       "24   [0.14732212, 0.024135005, 0.045808703, 0.07718...   both  \n",
       "27   [0.07632324, 0.00717866, 0.11950432, -0.000946...   both  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove NaN\n",
    "word_vec_df_both = word_vec_df_both.dropna()\n",
    "word_vec_df_both.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15232/897853209.py:6: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if type(x) == np.ndarray and type(x == np.ndarray):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_vec_avg_self</th>\n",
       "      <th>word_vec_avg_target</th>\n",
       "      <th>_merge</th>\n",
       "      <th>euclidean_distance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[-0.017000489, 0.021428036, 0.16119394, -0.009...</td>\n",
       "      <td>[0.006501836, 0.06303416, 0.18272737, 0.021416...</td>\n",
       "      <td>both</td>\n",
       "      <td>0.309452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.038041864, 0.046753965, 0.08819873, 0.00072...</td>\n",
       "      <td>[0.20633665, -0.07933207, 0.15059035, -0.01459...</td>\n",
       "      <td>both</td>\n",
       "      <td>0.391612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[-0.06192059, -0.11488108, 0.11417292, -0.0890...</td>\n",
       "      <td>[0.12936483, 0.014520218, -0.005053561, -0.024...</td>\n",
       "      <td>both</td>\n",
       "      <td>1.097579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[0.055738714, 0.007035163, 0.107713476, 0.1542...</td>\n",
       "      <td>[0.14732212, 0.024135005, 0.045808703, 0.07718...</td>\n",
       "      <td>both</td>\n",
       "      <td>0.568951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[0.097340696, -0.0072463155, 0.11122257, 0.002...</td>\n",
       "      <td>[0.07632324, 0.00717866, 0.11950432, -0.000946...</td>\n",
       "      <td>both</td>\n",
       "      <td>0.293323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     word_vec_avg_self  \\\n",
       "MID                                                      \n",
       "5    [-0.017000489, 0.021428036, 0.16119394, -0.009...   \n",
       "7    [0.038041864, 0.046753965, 0.08819873, 0.00072...   \n",
       "8    [-0.06192059, -0.11488108, 0.11417292, -0.0890...   \n",
       "24   [0.055738714, 0.007035163, 0.107713476, 0.1542...   \n",
       "27   [0.097340696, -0.0072463155, 0.11122257, 0.002...   \n",
       "\n",
       "                                   word_vec_avg_target _merge  \\\n",
       "MID                                                             \n",
       "5    [0.006501836, 0.06303416, 0.18272737, 0.021416...   both   \n",
       "7    [0.20633665, -0.07933207, 0.15059035, -0.01459...   both   \n",
       "8    [0.12936483, 0.014520218, -0.005053561, -0.024...   both   \n",
       "24   [0.14732212, 0.024135005, 0.045808703, 0.07718...   both   \n",
       "27   [0.07632324, 0.00717866, 0.11950432, -0.000946...   both   \n",
       "\n",
       "     euclidean_distance  \n",
       "MID                      \n",
       "5              0.309452  \n",
       "7              0.391612  \n",
       "8              1.097579  \n",
       "24             0.568951  \n",
       "27             0.293323  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Euclidean Distance\n",
    "# https://ashukumar27.medium.com/similarity-functions-in-python-aa6dfe721035\n",
    "import math\n",
    "\n",
    "def euclidean_distance(x, y):\n",
    "    if type(x) == np.ndarray and type(x == np.ndarray):\n",
    "        return math.sqrt(sum(pow(xi - yi, 2) for xi, yi in zip(x, y)))\n",
    "\n",
    "def euclidean_distance_df(x_ser, y_ser):\n",
    "    if type(x_ser) == pd.core.series.Series and type(y_ser) == pd.core.series.Series:\n",
    "        return [euclidean_distance(x, y) for x, y in zip(x_ser, y_ser)]\n",
    "\n",
    "word_vec_df_both['euclidean_distance'] = euclidean_distance_df(word_vec_df_both[\"word_vec_avg_self\"], word_vec_df_both[\"word_vec_avg_target\"])\n",
    "word_vec_df_both.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_vec_avg_self</th>\n",
       "      <th>word_vec_avg_target</th>\n",
       "      <th>_merge</th>\n",
       "      <th>euclidean_distance</th>\n",
       "      <th>manhattan_distance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[-0.017000489, 0.021428036, 0.16119394, -0.009...</td>\n",
       "      <td>[0.006501836, 0.06303416, 0.18272737, 0.021416...</td>\n",
       "      <td>both</td>\n",
       "      <td>0.309452</td>\n",
       "      <td>1.766482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.038041864, 0.046753965, 0.08819873, 0.00072...</td>\n",
       "      <td>[0.20633665, -0.07933207, 0.15059035, -0.01459...</td>\n",
       "      <td>both</td>\n",
       "      <td>0.391612</td>\n",
       "      <td>2.110458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[-0.06192059, -0.11488108, 0.11417292, -0.0890...</td>\n",
       "      <td>[0.12936483, 0.014520218, -0.005053561, -0.024...</td>\n",
       "      <td>both</td>\n",
       "      <td>1.097579</td>\n",
       "      <td>6.200497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[0.055738714, 0.007035163, 0.107713476, 0.1542...</td>\n",
       "      <td>[0.14732212, 0.024135005, 0.045808703, 0.07718...</td>\n",
       "      <td>both</td>\n",
       "      <td>0.568951</td>\n",
       "      <td>3.310129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[0.097340696, -0.0072463155, 0.11122257, 0.002...</td>\n",
       "      <td>[0.07632324, 0.00717866, 0.11950432, -0.000946...</td>\n",
       "      <td>both</td>\n",
       "      <td>0.293323</td>\n",
       "      <td>1.612408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     word_vec_avg_self  \\\n",
       "MID                                                      \n",
       "5    [-0.017000489, 0.021428036, 0.16119394, -0.009...   \n",
       "7    [0.038041864, 0.046753965, 0.08819873, 0.00072...   \n",
       "8    [-0.06192059, -0.11488108, 0.11417292, -0.0890...   \n",
       "24   [0.055738714, 0.007035163, 0.107713476, 0.1542...   \n",
       "27   [0.097340696, -0.0072463155, 0.11122257, 0.002...   \n",
       "\n",
       "                                   word_vec_avg_target _merge  \\\n",
       "MID                                                             \n",
       "5    [0.006501836, 0.06303416, 0.18272737, 0.021416...   both   \n",
       "7    [0.20633665, -0.07933207, 0.15059035, -0.01459...   both   \n",
       "8    [0.12936483, 0.014520218, -0.005053561, -0.024...   both   \n",
       "24   [0.14732212, 0.024135005, 0.045808703, 0.07718...   both   \n",
       "27   [0.07632324, 0.00717866, 0.11950432, -0.000946...   both   \n",
       "\n",
       "     euclidean_distance  manhattan_distance  \n",
       "MID                                          \n",
       "5              0.309452            1.766482  \n",
       "7              0.391612            2.110458  \n",
       "8              1.097579            6.200497  \n",
       "24             0.568951            3.310129  \n",
       "27             0.293323            1.612408  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manhattan Distance\n",
    "# https://ashukumar27.medium.com/similarity-functions-in-python-aa6dfe721035\n",
    "def manhattan_distance(x, y):\n",
    "    return sum(abs(xi - yi) for xi, yi in zip(x, y))\n",
    "\n",
    "def manhattan_distance_df(x_ser, y_ser):\n",
    "    if type(x_ser) == pd.core.series.Series and type(y_ser) == pd.core.series.Series:\n",
    "        return [manhattan_distance(x, y) for x, y in zip(x_ser, y_ser)]\n",
    "\n",
    "word_vec_df_both['manhattan_distance'] = manhattan_distance_df(word_vec_df_both[\"word_vec_avg_self\"], word_vec_df_both[\"word_vec_avg_target\"])\n",
    "word_vec_df_both.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_vec_avg_self</th>\n",
       "      <th>word_vec_avg_target</th>\n",
       "      <th>_merge</th>\n",
       "      <th>euclidean_distance</th>\n",
       "      <th>manhattan_distance</th>\n",
       "      <th>cosine_similarity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[-0.017000489, 0.021428036, 0.16119394, -0.009...</td>\n",
       "      <td>[0.006501836, 0.06303416, 0.18272737, 0.021416...</td>\n",
       "      <td>both</td>\n",
       "      <td>0.309452</td>\n",
       "      <td>1.766482</td>\n",
       "      <td>0.918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.038041864, 0.046753965, 0.08819873, 0.00072...</td>\n",
       "      <td>[0.20633665, -0.07933207, 0.15059035, -0.01459...</td>\n",
       "      <td>both</td>\n",
       "      <td>0.391612</td>\n",
       "      <td>2.110458</td>\n",
       "      <td>0.748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[-0.06192059, -0.11488108, 0.11417292, -0.0890...</td>\n",
       "      <td>[0.12936483, 0.014520218, -0.005053561, -0.024...</td>\n",
       "      <td>both</td>\n",
       "      <td>1.097579</td>\n",
       "      <td>6.200497</td>\n",
       "      <td>0.398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[0.055738714, 0.007035163, 0.107713476, 0.1542...</td>\n",
       "      <td>[0.14732212, 0.024135005, 0.045808703, 0.07718...</td>\n",
       "      <td>both</td>\n",
       "      <td>0.568951</td>\n",
       "      <td>3.310129</td>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[0.097340696, -0.0072463155, 0.11122257, 0.002...</td>\n",
       "      <td>[0.07632324, 0.00717866, 0.11950432, -0.000946...</td>\n",
       "      <td>both</td>\n",
       "      <td>0.293323</td>\n",
       "      <td>1.612408</td>\n",
       "      <td>0.878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     word_vec_avg_self  \\\n",
       "MID                                                      \n",
       "5    [-0.017000489, 0.021428036, 0.16119394, -0.009...   \n",
       "7    [0.038041864, 0.046753965, 0.08819873, 0.00072...   \n",
       "8    [-0.06192059, -0.11488108, 0.11417292, -0.0890...   \n",
       "24   [0.055738714, 0.007035163, 0.107713476, 0.1542...   \n",
       "27   [0.097340696, -0.0072463155, 0.11122257, 0.002...   \n",
       "\n",
       "                                   word_vec_avg_target _merge  \\\n",
       "MID                                                             \n",
       "5    [0.006501836, 0.06303416, 0.18272737, 0.021416...   both   \n",
       "7    [0.20633665, -0.07933207, 0.15059035, -0.01459...   both   \n",
       "8    [0.12936483, 0.014520218, -0.005053561, -0.024...   both   \n",
       "24   [0.14732212, 0.024135005, 0.045808703, 0.07718...   both   \n",
       "27   [0.07632324, 0.00717866, 0.11950432, -0.000946...   both   \n",
       "\n",
       "     euclidean_distance  manhattan_distance  cosine_similarity  \n",
       "MID                                                             \n",
       "5              0.309452            1.766482              0.918  \n",
       "7              0.391612            2.110458              0.748  \n",
       "8              1.097579            6.200497              0.398  \n",
       "24             0.568951            3.310129              0.775  \n",
       "27             0.293323            1.612408              0.878  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cosine Similairty\n",
    "# https://ashukumar27.medium.com/similarity-functions-in-python-aa6dfe721035\n",
    "def square_rooted(x):\n",
    "    return round(math.sqrt(sum([xi*xi for xi in x])), 3)\n",
    "\n",
    "def cosine_similarity(x, y):\n",
    "    numerator = sum(xi*yi for xi, yi in zip(x, y))\n",
    "    denominator = square_rooted(x) * square_rooted(y)\n",
    "    return round(numerator / float(denominator), 3)\n",
    "\n",
    "def cosine_similarity_df(x_ser, y_ser):\n",
    "    if type(x_ser) == pd.core.series.Series and type(y_ser) == pd.core.series.Series:\n",
    "        return [cosine_similarity(x, y) for x, y in zip(x_ser, y_ser)]\n",
    "\n",
    "word_vec_df_both['cosine_similarity'] = cosine_similarity_df(word_vec_df_both[\"word_vec_avg_self\"], word_vec_df_both[\"word_vec_avg_target\"])\n",
    "word_vec_df_both.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation\n",
    "High IOS group (5, 6, 7) and Low IOS group (1, 2, and 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>rt</th>\n",
       "      <th>self_sex</th>\n",
       "      <th>self_age</th>\n",
       "      <th>residence</th>\n",
       "      <th>participation</th>\n",
       "      <th>IOS_score</th>\n",
       "      <th>target_likedislike</th>\n",
       "      <th>target_sex</th>\n",
       "      <th>...</th>\n",
       "      <th>self_activeness_score</th>\n",
       "      <th>self_sociability_score</th>\n",
       "      <th>target_tolerance_score</th>\n",
       "      <th>target_pleasantness_score</th>\n",
       "      <th>target_responsibility_score</th>\n",
       "      <th>target_carefulness_score</th>\n",
       "      <th>target_activeness_score</th>\n",
       "      <th>target_sociability_score</th>\n",
       "      <th>completion</th>\n",
       "      <th>stratumID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>2024/02/16-12:21:18</td>\n",
       "      <td>2024/02/16-12:24:31</td>\n",
       "      <td>193.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>COMP</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>2024/02/16-12:23:21</td>\n",
       "      <td>2024/02/16-12:25:38</td>\n",
       "      <td>137.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>COMP</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>2024/02/16-12:20:52</td>\n",
       "      <td>2024/02/16-12:25:45</td>\n",
       "      <td>293.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>COMP</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>2024/02/16-12:24:28</td>\n",
       "      <td>2024/02/16-12:26:11</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>COMP</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11.0</th>\n",
       "      <td>2024/02/16-12:23:46</td>\n",
       "      <td>2024/02/16-12:26:26</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>COMP</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    start                  end     rt  self_sex  self_age  \\\n",
       "MID                                                                         \n",
       "2.0   2024/02/16-12:21:18  2024/02/16-12:24:31  193.0       1.0      45.0   \n",
       "5.0   2024/02/16-12:23:21  2024/02/16-12:25:38  137.0       1.0      36.0   \n",
       "7.0   2024/02/16-12:20:52  2024/02/16-12:25:45  293.0       1.0      54.0   \n",
       "8.0   2024/02/16-12:24:28  2024/02/16-12:26:11  103.0       1.0      36.0   \n",
       "11.0  2024/02/16-12:23:46  2024/02/16-12:26:26  160.0       1.0      56.0   \n",
       "\n",
       "      residence  participation  IOS_score  target_likedislike  target_sex  \\\n",
       "MID                                                                         \n",
       "2.0        28.0            1.0        5.0                 3.0         2.0   \n",
       "5.0        28.0            1.0        2.0                 4.0         2.0   \n",
       "7.0        12.0            1.0        5.0                 1.0         2.0   \n",
       "8.0        14.0            1.0        1.0                 1.0         2.0   \n",
       "11.0       13.0            1.0        2.0                 1.0         2.0   \n",
       "\n",
       "      ...  self_activeness_score self_sociability_score  \\\n",
       "MID   ...                                                 \n",
       "2.0   ...                    5.0                    2.0   \n",
       "5.0   ...                    4.0                    2.0   \n",
       "7.0   ...                    5.0                    3.0   \n",
       "8.0   ...                    3.0                    3.0   \n",
       "11.0  ...                    4.0                    4.0   \n",
       "\n",
       "      target_tolerance_score  target_pleasantness_score  \\\n",
       "MID                                                       \n",
       "2.0                      6.0                        5.0   \n",
       "5.0                      5.0                        3.0   \n",
       "7.0                      1.0                        7.0   \n",
       "8.0                      1.0                        7.0   \n",
       "11.0                     4.0                        4.0   \n",
       "\n",
       "      target_responsibility_score  target_carefulness_score  \\\n",
       "MID                                                           \n",
       "2.0                           1.0                       4.0   \n",
       "5.0                           6.0                       2.0   \n",
       "7.0                           1.0                       6.0   \n",
       "8.0                           1.0                       5.0   \n",
       "11.0                          4.0                       4.0   \n",
       "\n",
       "      target_activeness_score  target_sociability_score  completion  stratumID  \n",
       "MID                                                                             \n",
       "2.0                       7.0                       6.0        COMP        5.0  \n",
       "5.0                       5.0                       3.0        COMP        9.0  \n",
       "7.0                       6.0                       2.0        COMP        5.0  \n",
       "8.0                       4.0                       7.0        COMP        1.0  \n",
       "11.0                      4.0                       4.0        COMP        2.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./Results/output01_all.csv', header=0, index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "HighIOS_indices = df['IOS_score'] > 4\n",
    "LowIOS_indices = df['IOS_score'] < 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>rt</th>\n",
       "      <th>self_sex</th>\n",
       "      <th>self_age</th>\n",
       "      <th>residence</th>\n",
       "      <th>participation</th>\n",
       "      <th>IOS_score</th>\n",
       "      <th>target_likedislike</th>\n",
       "      <th>target_sex</th>\n",
       "      <th>...</th>\n",
       "      <th>self_sociability_score</th>\n",
       "      <th>target_tolerance_score</th>\n",
       "      <th>target_pleasantness_score</th>\n",
       "      <th>target_responsibility_score</th>\n",
       "      <th>target_carefulness_score</th>\n",
       "      <th>target_activeness_score</th>\n",
       "      <th>target_sociability_score</th>\n",
       "      <th>completion</th>\n",
       "      <th>stratumID</th>\n",
       "      <th>IOS_group</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>2024/02/16-12:21:18</td>\n",
       "      <td>2024/02/16-12:24:31</td>\n",
       "      <td>193.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>COMP</td>\n",
       "      <td>5.0</td>\n",
       "      <td>HighIOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>2024/02/16-12:23:21</td>\n",
       "      <td>2024/02/16-12:25:38</td>\n",
       "      <td>137.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>COMP</td>\n",
       "      <td>9.0</td>\n",
       "      <td>LowIOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>2024/02/16-12:20:52</td>\n",
       "      <td>2024/02/16-12:25:45</td>\n",
       "      <td>293.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>COMP</td>\n",
       "      <td>5.0</td>\n",
       "      <td>HighIOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>2024/02/16-12:24:28</td>\n",
       "      <td>2024/02/16-12:26:11</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>COMP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>LowIOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11.0</th>\n",
       "      <td>2024/02/16-12:23:46</td>\n",
       "      <td>2024/02/16-12:26:26</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>COMP</td>\n",
       "      <td>2.0</td>\n",
       "      <td>LowIOS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    start                  end     rt  self_sex  self_age  \\\n",
       "MID                                                                         \n",
       "2.0   2024/02/16-12:21:18  2024/02/16-12:24:31  193.0       1.0      45.0   \n",
       "5.0   2024/02/16-12:23:21  2024/02/16-12:25:38  137.0       1.0      36.0   \n",
       "7.0   2024/02/16-12:20:52  2024/02/16-12:25:45  293.0       1.0      54.0   \n",
       "8.0   2024/02/16-12:24:28  2024/02/16-12:26:11  103.0       1.0      36.0   \n",
       "11.0  2024/02/16-12:23:46  2024/02/16-12:26:26  160.0       1.0      56.0   \n",
       "\n",
       "      residence  participation  IOS_score  target_likedislike  target_sex  \\\n",
       "MID                                                                         \n",
       "2.0        28.0            1.0        5.0                 3.0         2.0   \n",
       "5.0        28.0            1.0        2.0                 4.0         2.0   \n",
       "7.0        12.0            1.0        5.0                 1.0         2.0   \n",
       "8.0        14.0            1.0        1.0                 1.0         2.0   \n",
       "11.0       13.0            1.0        2.0                 1.0         2.0   \n",
       "\n",
       "      ...  self_sociability_score target_tolerance_score  \\\n",
       "MID   ...                                                  \n",
       "2.0   ...                     2.0                    6.0   \n",
       "5.0   ...                     2.0                    5.0   \n",
       "7.0   ...                     3.0                    1.0   \n",
       "8.0   ...                     3.0                    1.0   \n",
       "11.0  ...                     4.0                    4.0   \n",
       "\n",
       "      target_pleasantness_score  target_responsibility_score  \\\n",
       "MID                                                            \n",
       "2.0                         5.0                          1.0   \n",
       "5.0                         3.0                          6.0   \n",
       "7.0                         7.0                          1.0   \n",
       "8.0                         7.0                          1.0   \n",
       "11.0                        4.0                          4.0   \n",
       "\n",
       "      target_carefulness_score  target_activeness_score  \\\n",
       "MID                                                       \n",
       "2.0                        4.0                      7.0   \n",
       "5.0                        2.0                      5.0   \n",
       "7.0                        6.0                      6.0   \n",
       "8.0                        5.0                      4.0   \n",
       "11.0                       4.0                      4.0   \n",
       "\n",
       "      target_sociability_score  completion  stratumID  IOS_group  \n",
       "MID                                                               \n",
       "2.0                        6.0        COMP        5.0    HighIOS  \n",
       "5.0                        3.0        COMP        9.0     LowIOS  \n",
       "7.0                        2.0        COMP        5.0    HighIOS  \n",
       "8.0                        7.0        COMP        1.0     LowIOS  \n",
       "11.0                       4.0        COMP        2.0     LowIOS  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df にIOS_group列を追加\n",
    "df['IOS_group'] = ['NA'] * len(df)\n",
    "df.loc[HighIOS_indices, ['IOS_group']] = 'HighIOS'\n",
    "df.loc[LowIOS_indices, ['IOS_group']] = 'LowIOS'\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, ['IOS_score', 'IOS_group']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IOS_score</th>\n",
       "      <th>IOS_group</th>\n",
       "      <th>word_vec_avg_self</th>\n",
       "      <th>word_vec_avg_target</th>\n",
       "      <th>_merge</th>\n",
       "      <th>euclidean_distance</th>\n",
       "      <th>manhattan_distance</th>\n",
       "      <th>cosine_similarity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>LowIOS</td>\n",
       "      <td>[-0.017000489, 0.021428036, 0.16119394, -0.009...</td>\n",
       "      <td>[0.006501836, 0.06303416, 0.18272737, 0.021416...</td>\n",
       "      <td>both</td>\n",
       "      <td>0.309452</td>\n",
       "      <td>1.766482</td>\n",
       "      <td>0.918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>HighIOS</td>\n",
       "      <td>[0.038041864, 0.046753965, 0.08819873, 0.00072...</td>\n",
       "      <td>[0.20633665, -0.07933207, 0.15059035, -0.01459...</td>\n",
       "      <td>both</td>\n",
       "      <td>0.391612</td>\n",
       "      <td>2.110458</td>\n",
       "      <td>0.748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>LowIOS</td>\n",
       "      <td>[-0.06192059, -0.11488108, 0.11417292, -0.0890...</td>\n",
       "      <td>[0.12936483, 0.014520218, -0.005053561, -0.024...</td>\n",
       "      <td>both</td>\n",
       "      <td>1.097579</td>\n",
       "      <td>6.200497</td>\n",
       "      <td>0.398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>[0.055738714, 0.007035163, 0.107713476, 0.1542...</td>\n",
       "      <td>[0.14732212, 0.024135005, 0.045808703, 0.07718...</td>\n",
       "      <td>both</td>\n",
       "      <td>0.568951</td>\n",
       "      <td>3.310129</td>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>LowIOS</td>\n",
       "      <td>[0.097340696, -0.0072463155, 0.11122257, 0.002...</td>\n",
       "      <td>[0.07632324, 0.00717866, 0.11950432, -0.000946...</td>\n",
       "      <td>both</td>\n",
       "      <td>0.293323</td>\n",
       "      <td>1.612408</td>\n",
       "      <td>0.878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      IOS_score IOS_group                                  word_vec_avg_self  \\\n",
       "MID                                                                            \n",
       "5.0         2.0    LowIOS  [-0.017000489, 0.021428036, 0.16119394, -0.009...   \n",
       "7.0         5.0   HighIOS  [0.038041864, 0.046753965, 0.08819873, 0.00072...   \n",
       "8.0         1.0    LowIOS  [-0.06192059, -0.11488108, 0.11417292, -0.0890...   \n",
       "24.0        4.0        NA  [0.055738714, 0.007035163, 0.107713476, 0.1542...   \n",
       "27.0        1.0    LowIOS  [0.097340696, -0.0072463155, 0.11122257, 0.002...   \n",
       "\n",
       "                                    word_vec_avg_target _merge  \\\n",
       "MID                                                              \n",
       "5.0   [0.006501836, 0.06303416, 0.18272737, 0.021416...   both   \n",
       "7.0   [0.20633665, -0.07933207, 0.15059035, -0.01459...   both   \n",
       "8.0   [0.12936483, 0.014520218, -0.005053561, -0.024...   both   \n",
       "24.0  [0.14732212, 0.024135005, 0.045808703, 0.07718...   both   \n",
       "27.0  [0.07632324, 0.00717866, 0.11950432, -0.000946...   both   \n",
       "\n",
       "      euclidean_distance  manhattan_distance  cosine_similarity  \n",
       "MID                                                              \n",
       "5.0             0.309452            1.766482              0.918  \n",
       "7.0             0.391612            2.110458              0.748  \n",
       "8.0             1.097579            6.200497              0.398  \n",
       "24.0            0.568951            3.310129              0.775  \n",
       "27.0            0.293323            1.612408              0.878  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# overlap_magnitude_df と df.loc[:, ['IOS_score', 'IOS_group']] をマージ（key=MID)\n",
    "out_df = pd.merge(df.loc[:, ['IOS_score', 'IOS_group']], word_vec_df_both, on='MID')\n",
    "# # さらにword_vec_df_bothをマージ\n",
    "# out_df = pd.merge(out_df, word_vec_df_both, on='MID')\n",
    "\n",
    "out_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # overlap_magnitude_df と df.loc[:, ['MID', 'IOS_group']] をマージ（key=MID)\n",
    "# out_df = pd.merge(overlap_magnitude_df, df.loc[:, ['MID', 'IOS_score', 'IOS_group']], on='MID')\n",
    "\n",
    "filename = './Results/output02.csv'\n",
    "out_df.to_csv(filename, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確認用\n",
    "sentences_token_self_df = pd.DataFrame(sentences_token_self).rename(columns={0: 'MID'})\n",
    "sentences_token_self_df = sentences_token_self_df.set_index('MID')\n",
    "sentences_token_self_df.to_csv('./Results/sentences_token_self_df.csv', index=False)\n",
    "\n",
    "sentences_token_target_df = pd.DataFrame(sentences_token_target).rename(columns={0: 'MID'})\n",
    "sentences_token_target_df = sentences_token_target_df.set_index('MID')\n",
    "sentences_token_target_df.to_csv('./Results/sentences_token_target_df.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myproject02",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
